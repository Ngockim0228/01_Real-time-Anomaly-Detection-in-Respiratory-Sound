{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "import pywt\n",
    "from skimage.feature import greycomatrix\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "import itertools\n",
    "import os\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "kl = keras.layers\n",
    "import skimage\n",
    "import random\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "# tf.keras.utils.set_random_seed(seed_value)\n",
    "# tf.random.set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1651045513744,
     "user": {
      "displayName": "Kim-Ngoc Thi Le",
      "userId": "07740631987100063646"
     },
     "user_tz": -540
    },
    "id": "T4ytbxdVk_8B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import*\n",
    "# =============================================================================\n",
    "# source_dir\n",
    "# =============================================================================\n",
    "# source_dir='C://Users//Kim-Ngoc//Desktop//CODE//'\n",
    "source_dir= 'D://Fundus//Lung sound//V5_mspec_8s_4gr//'\n",
    "# =============================================================================\n",
    "# load mat files\n",
    "# =============================================================================\n",
    "covid_features=sio.loadmat(os.path.join(source_dir,'2gr_abnormal_322.mat')) \n",
    "covid_features=covid_features['abnormal'] \n",
    "\n",
    "normal_features=sio.loadmat(os.path.join(source_dir,'2gr_normal_322.mat')) \n",
    "normal_features=normal_features['normal']  \n",
    "\n",
    "# pneumonia_features=sio.loadmat(os.path.join(source_dir,'pneumonia.mat')) \n",
    "# pneumonia_features=pneumonia_features['pneumonia']    \n",
    "# =============================================================================\n",
    "# devide feature pool into inputs and target labels\n",
    "# =============================================================================\n",
    "X=np.concatenate((covid_features[:,:-1],normal_features[:,:-1]), axis=0)#inputs\n",
    "y=np.concatenate((covid_features[:,-1],normal_features[:,-1]), axis=0)#target labels\n",
    "# =============================================================================\n",
    "# normalization\n",
    "# =============================================================================\n",
    "min_max_scaler=MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X) \n",
    "# =============================================================================\n",
    "# feature reduction (K-PCA)\n",
    "# =============================================================================\n",
    "transformer = KernelPCA(n_components=128, kernel='linear')\n",
    "X = transformer.fit_transform(X)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as kl\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.random.set_seed(42)\n",
    "# Define function to build model with specified random seed\n",
    "def build_model(feature_size, n_classes, seed_value, dropout):\n",
    "    \"\"\" Build a small model for multi-label classification \"\"\"\n",
    "    inp = kl.Input((feature_size,))\n",
    "    x = kl.Dense(512, activation='relu')(inp)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(512, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(512, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(256, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(128, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(64, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(32, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    out = kl.Dense(n_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.metrics import binary_accuracy, Precision, Recall\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "# y = to_categorical(y, num_classes=2)\n",
    "best_test_acc = 0.0\n",
    "best_model = None\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "model = build_model(feature_size=X_train.shape[-1], n_classes=y_train.shape[-1], seed_value=42, dropout=0.1)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), \n",
    "                       tf.keras.metrics.Recall()]) \n",
    "model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test))\n",
    "test_metrics = model.evaluate(X_test, y_test)\n",
    "test_acc = test_metrics[1]\n",
    "if test_acc > best_test_acc:\n",
    "    best_test_acc = test_acc\n",
    "    best_model = model\n",
    "best_model.save(f'./model_seed/Linet/Main_V2/feature_128/model_4_6_bs_128.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Evaluate the model on the test set\n",
    "test_metrics = best_model.evaluate(X_test, y_test)\n",
    "print('Test loss:', test_metrics[0])\n",
    "print('Test accuracy:', test_metrics[1])\n",
    "print('Test precision: ', test_metrics[2])\n",
    "print('Test recall: ', test_metrics[3])\n",
    "f1_score = 2*test_metrics[2]*test_metrics[3]/(test_metrics[2] + test_metrics[3])\n",
    "print('Test F1: ', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "y_test = np.argmax(y_test, axis = 1)\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confus_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confus_matrix)\n",
    "se = confus_matrix[0][0]/(confus_matrix[0][1] + confus_matrix[0][0])\n",
    "sp = confus_matrix[1][1]/(confus_matrix[1][0] + confus_matrix[1][1])\n",
    "sc = (se+sp)/2\n",
    "print('Specificity Sp:', sp)\n",
    "print('Sensitivity Se:', se)\n",
    "print('Score Sc:', sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results in a .txt file\n",
    "with open('./model_seed/Linet/Main_V2/feature_128/results_4_6_bs_128.txt', 'w') as file:\n",
    "    file.write('Test loss: {}\\n'.format(test_metrics[0]))\n",
    "    file.write('Test accuracy: {}\\n'.format(test_metrics[1]))\n",
    "    file.write('Test precision: {}\\n'.format(test_metrics[2]))\n",
    "    file.write('Test recall: {}\\n'.format(test_metrics[3]))\n",
    "    file.write('Test F1 score: {}\\n'.format(f1_score))\n",
    "    file.write('Specificity Sp: {}\\n'.format(sp))\n",
    "    file.write('Sensitivity Se: {}\\n'.format(se))\n",
    "    file.write('Score Sc: {}\\n'.format(sc))\n",
    "    file.write('CM: {}\\n'.format(confus_matrix))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO2XDhsWEzclOmJ8gvQLOEi",
   "name": "Covid_3gr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
