{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "import pywt\n",
    "from skimage.feature import greycomatrix\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "import itertools\n",
    "import os\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "kl = keras.layers\n",
    "import skimage\n",
    "import random\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "# tf.keras.utils.set_random_seed(seed_value)\n",
    "# tf.random.set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1651045513744,
     "user": {
      "displayName": "Kim-Ngoc Thi Le",
      "userId": "07740631987100063646"
     },
     "user_tz": -540
    },
    "id": "T4ytbxdVk_8B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import*\n",
    "# =============================================================================\n",
    "# source_dir\n",
    "# =============================================================================\n",
    "# source_dir='C://Users//Kim-Ngoc//Desktop//CODE//'\n",
    "source_dir= 'D://Fundus//Lung sound//V5_mspec_8s_4gr//'\n",
    "# =============================================================================\n",
    "# load mat files\n",
    "# =============================================================================\n",
    "covid_features=sio.loadmat(os.path.join(source_dir,'2gr_abnormal_322.mat')) \n",
    "covid_features=covid_features['abnormal'] \n",
    "\n",
    "normal_features=sio.loadmat(os.path.join(source_dir,'2gr_normal_322.mat')) \n",
    "normal_features=normal_features['normal']  \n",
    "\n",
    "# pneumonia_features=sio.loadmat(os.path.join(source_dir,'pneumonia.mat')) \n",
    "# pneumonia_features=pneumonia_features['pneumonia']    \n",
    "# =============================================================================\n",
    "# devide feature pool into inputs and target labels\n",
    "# =============================================================================\n",
    "X=np.concatenate((covid_features[:,:-1],normal_features[:,:-1]), axis=0)#inputs\n",
    "y=np.concatenate((covid_features[:,-1],normal_features[:,-1]), axis=0)#target labels\n",
    "# =============================================================================\n",
    "# normalization\n",
    "# =============================================================================\n",
    "min_max_scaler=MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X) \n",
    "# =============================================================================\n",
    "# feature reduction (K-PCA)\n",
    "# =============================================================================\n",
    "transformer = KernelPCA(n_components=128, kernel='linear')\n",
    "X = transformer.fit_transform(X)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as kl\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.random.set_seed(42)\n",
    "# Define function to build model with specified random seed\n",
    "def build_model(feature_size, n_classes, seed_value, dropout):\n",
    "    \"\"\" Build a small model for multi-label classification \"\"\"\n",
    "    inp = kl.Input((feature_size,))\n",
    "    x = kl.Dense(512, activation='relu')(inp)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(512, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(512, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(256, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(128, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(64, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    x = kl.Dense(32, activation='relu')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(dropout)(x)\n",
    "    out = kl.Dense(n_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.metrics import binary_accuracy, Precision, Recall\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "confusion_matrices = []\n",
    "\n",
    "best_test_acc = 0.0\n",
    "best_model = None\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(X, y.argmax(1))):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    # y_train = y_train.ravel()\n",
    "    # y_val = y_val.ravel()\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = build_model(feature_size=X_train.shape[-1], n_classes=y_train.shape[-1], seed_value=42, dropout=0.1)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[binary_accuracy, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_val, y_val))\n",
    "    val_metrics = model.evaluate(X_val, y_val)\n",
    "    test_acc = val_metrics[1]\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_model = model\n",
    "    # Evaluate the model on the validation set\n",
    "    val_metrics = best_model.evaluate(X_val, y_val)\n",
    "    accuracies.append(val_metrics[1])\n",
    "    precisions.append(val_metrics[2])\n",
    "    recalls.append(val_metrics[3])\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    cm = confusion_matrix(np.argmax(y_val, axis=1),y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    # Save the model\n",
    "    best_model.save(f'./model_seed/Linet/Main_V2/feature_128/5f_bs_128_v1/model_{i}.h5')\n",
    "    # Reset the model for the next fold\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the average metrics across all folds\n",
    "avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "avg_precision = sum(precisions) / len(precisions)\n",
    "avg_recall = sum(recalls) / len(recalls)\n",
    "\n",
    "print('Average Accuracy:', avg_accuracy)\n",
    "print('Average Precision:', avg_precision)\n",
    "print('Average Recall:', avg_recall)\n",
    "\n",
    "# Calculate the average confusion matrix across all folds\n",
    "avg_cm = sum(confusion_matrices) / len(confusion_matrices)\n",
    "print('Average Confusion Matrix:')\n",
    "print(avg_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "se = avg_cm[0][0]/(avg_cm[1][0] + avg_cm[0][0])\n",
    "sp = avg_cm[1][1]/(avg_cm[0][1] + avg_cm[1][1])\n",
    "sc = (se+sp)/2\n",
    "print('Specificity Sp:', sp)\n",
    "print('Sensitivity Se:', se)\n",
    "print('Score Sc:', sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results in a .txt file\n",
    "with open('./model_seed/Linet/Main_V2/feature_128/5f_bs_128_v1/results_5folds.txt', 'w') as file:\n",
    "    file.write('Test accuracy: {}\\n'.format(avg_accuracy))\n",
    "    file.write('Test precision: {}\\n'.format(avg_precision))\n",
    "    file.write('Test recall: {}\\n'.format(avg_recall))\n",
    "    file.write('Test F1 score: {}\\n'.format(2*avg_precision*avg_recall/(avg_recall + avg_precision)))\n",
    "    file.write('Specificity Sp: {}\\n'.format(sp))\n",
    "    file.write('Sensitivity Se: {}\\n'.format(se))\n",
    "    file.write('Score Sc: {}\\n'.format(sc))\n",
    "    file.write('CM: {}\\n'.format(avg_cm))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO2XDhsWEzclOmJ8gvQLOEi",
   "name": "Covid_3gr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
